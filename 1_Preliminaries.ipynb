{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data_loader with no vocab from pickle file example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.05s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] Tokenizing captions...\n",
      "[100000/414113] Tokenizing captions...\n",
      "[200000/414113] Tokenizing captions...\n",
      "[300000/414113] Tokenizing captions...\n",
      "[400000/414113] Tokenizing captions...\n",
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 414113/414113 [00:32<00:00, 12907.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=False,\n",
    "                         cocoapi_loc ='../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_caption = 'A person doing a trick on a rail while riding a skateboard.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'person', 'doing', 'a', 'trick', 'on', 'a', 'rail', 'while', 'riding', 'a', 'skateboard', '.']\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "\n",
    "sample_tokens = nltk.tokenize.word_tokenize(str(sample_caption).lower())\n",
    "print(sample_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special start word: <start>\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "sample_caption = []\n",
    "\n",
    "start_word = data_loader.dataset.vocab.start_word\n",
    "print('Special start word:', start_word)\n",
    "sample_caption.append(data_loader.dataset.vocab(start_word))\n",
    "print(sample_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 98, 754, 3, 396, 39, 3, 1009, 207, 139, 3, 753, 18]\n"
     ]
    }
   ],
   "source": [
    "sample_caption.extend([data_loader.dataset.vocab(token) for token in sample_tokens])\n",
    "print(sample_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special end word: <end>\n",
      "[0, 3, 98, 754, 3, 396, 39, 3, 1009, 207, 139, 3, 753, 18, 1]\n"
     ]
    }
   ],
   "source": [
    "end_word = data_loader.dataset.vocab.end_word\n",
    "print('Special end word:', end_word)\n",
    "\n",
    "sample_caption.append(data_loader.dataset.vocab(end_word))\n",
    "print(sample_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,     3,    98,   754,     3,   396,    39,     3,  1009,\n",
      "          207,   139,     3,   753,    18,     1])\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "\n",
    "sample_caption = torch.Tensor(sample_caption).long()\n",
    "print(sample_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 0,\n",
       " '<end>': 1,\n",
       " '<unk>': 2,\n",
       " 'a': 3,\n",
       " 'very': 4,\n",
       " 'clean': 5,\n",
       " 'and': 6,\n",
       " 'well': 7,\n",
       " 'decorated': 8,\n",
       " 'empty': 9,\n",
       " 'bathroom': 10,\n",
       " 'panoramic': 11,\n",
       " 'view': 12,\n",
       " 'of': 13,\n",
       " 'kitchen': 14,\n",
       " 'all': 15,\n",
       " 'its': 16,\n",
       " 'appliances': 17,\n",
       " '.': 18,\n",
       " 'blue': 19,\n",
       " 'white': 20,\n",
       " 'with': 21,\n",
       " 'butterfly': 22,\n",
       " 'themed': 23,\n",
       " 'wall': 24,\n",
       " 'tiles': 25,\n",
       " 'photo': 26,\n",
       " 'dining': 27,\n",
       " 'room': 28,\n",
       " 'stop': 29,\n",
       " 'sign': 30,\n",
       " 'across': 31,\n",
       " 'the': 32,\n",
       " 'street': 33,\n",
       " 'from': 34,\n",
       " 'red': 35,\n",
       " 'car': 36,\n",
       " 'vandalized': 37,\n",
       " 'beetle': 38,\n",
       " 'on': 39,\n",
       " 'road': 40,\n",
       " 'border': 41,\n",
       " 'butterflies': 42,\n",
       " 'paint': 43,\n",
       " 'walls': 44,\n",
       " 'above': 45,\n",
       " 'it': 46,\n",
       " 'an': 47,\n",
       " 'angled': 48,\n",
       " 'beautifully': 49,\n",
       " 'two': 50,\n",
       " 'people': 51,\n",
       " 'are': 52,\n",
       " 'walking': 53,\n",
       " 'down': 54,\n",
       " 'beach': 55,\n",
       " 'sink': 56,\n",
       " 'toilet': 57,\n",
       " 'inside': 58,\n",
       " 'small': 59,\n",
       " 'black': 60,\n",
       " 'square': 61,\n",
       " 'tile': 62,\n",
       " 'floor': 63,\n",
       " 'that': 64,\n",
       " 'needs': 65,\n",
       " 'repairs': 66,\n",
       " 'vanity': 67,\n",
       " 'contains': 68,\n",
       " 'sinks': 69,\n",
       " 'towel': 70,\n",
       " 'for': 71,\n",
       " 'each': 72,\n",
       " 'several': 73,\n",
       " 'metal': 74,\n",
       " 'balls': 75,\n",
       " 'sit': 76,\n",
       " 'in': 77,\n",
       " 'sand': 78,\n",
       " 'near': 79,\n",
       " 'group': 80,\n",
       " 'carrying': 81,\n",
       " 'surf': 82,\n",
       " 'boards': 83,\n",
       " 'brown': 84,\n",
       " 'cabinets': 85,\n",
       " ',': 86,\n",
       " 'backsplash': 87,\n",
       " 'grey': 88,\n",
       " 'counters': 89,\n",
       " 'surfer': 90,\n",
       " 'woman': 91,\n",
       " 'child': 92,\n",
       " 'walk': 93,\n",
       " 'few': 94,\n",
       " 'dim': 95,\n",
       " 'transportation': 96,\n",
       " 'system': 97,\n",
       " 'person': 98,\n",
       " 'protected': 99}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the word2idx dictionary.\n",
    "dict(list(data_loader.dataset.vocab.word2idx.items())[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in vocabulary: 8856\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of keys in the word2idx dictionary.\n",
    "print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] Tokenizing captions...\n",
      "[100000/414113] Tokenizing captions...\n",
      "[200000/414113] Tokenizing captions...\n",
      "[300000/414113] Tokenizing captions...\n",
      "[400000/414113] Tokenizing captions...\n",
      "loading annotations into memory...\n",
      "Done (t=0.64s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 414113/414113 [00:32<00:00, 12754.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Modify the minimum word count threshold.\n",
    "vocab_threshold = 5#original is 5\n",
    "\n",
    "# Obtain the data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=False,\n",
    "                        cocoapi_loc ='../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in vocabulary: 8856\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of keys in the word2idx dictionary.\n",
    "print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special unknown word: <unk>\n",
      "All unknown words are mapped to this integer: 2\n"
     ]
    }
   ],
   "source": [
    "unk_word = data_loader.dataset.vocab.unk_word\n",
    "print('Special unknown word:', unk_word)\n",
    "\n",
    "print('All unknown words are mapped to this integer:', data_loader.dataset.vocab(unk_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data_loader with vocab from pickle file example\n",
    "\n",
    "Once we save the tokenized vocab then we can directly use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 414113/414113 [00:32<00:00, 12851.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the data loader (from file). Note that it runs much faster than before!\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_from_file=True,\n",
    "                          cocoapi_loc ='../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in vocabulary: 8856\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of keys in the word2idx dictionary.\n",
    "print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Use the Data Loader to Obtain Batches\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: 10 --- count: 86334\n",
      "value: 11 --- count: 79948\n",
      "value:  9 --- count: 71935\n",
      "value: 12 --- count: 57637\n",
      "value: 13 --- count: 37646\n",
      "value: 14 --- count: 22335\n",
      "value:  8 --- count: 20769\n",
      "value: 15 --- count: 12841\n",
      "value: 16 --- count:  7729\n",
      "value: 17 --- count:  4842\n",
      "value: 18 --- count:  3104\n",
      "value: 19 --- count:  2014\n",
      "value:  7 --- count:  1597\n",
      "value: 20 --- count:  1451\n",
      "value: 21 --- count:   999\n",
      "value: 22 --- count:   683\n",
      "value: 23 --- count:   534\n",
      "value: 24 --- count:   383\n",
      "value: 25 --- count:   277\n",
      "value: 26 --- count:   215\n",
      "value: 27 --- count:   159\n",
      "value: 28 --- count:   115\n",
      "value: 29 --- count:    86\n",
      "value: 30 --- count:    58\n",
      "value: 31 --- count:    49\n",
      "value: 32 --- count:    44\n",
      "value: 34 --- count:    39\n",
      "value: 37 --- count:    32\n",
      "value: 33 --- count:    31\n",
      "value: 35 --- count:    31\n",
      "value: 36 --- count:    26\n",
      "value: 38 --- count:    18\n",
      "value: 39 --- count:    18\n",
      "value: 43 --- count:    16\n",
      "value: 44 --- count:    16\n",
      "value: 48 --- count:    12\n",
      "value: 45 --- count:    11\n",
      "value: 42 --- count:    10\n",
      "value: 40 --- count:     9\n",
      "value: 49 --- count:     9\n",
      "value: 46 --- count:     9\n",
      "value: 47 --- count:     7\n",
      "value: 50 --- count:     6\n",
      "value: 51 --- count:     6\n",
      "value: 41 --- count:     6\n",
      "value: 52 --- count:     5\n",
      "value: 54 --- count:     3\n",
      "value: 56 --- count:     2\n",
      "value:  6 --- count:     2\n",
      "value: 53 --- count:     2\n",
      "value: 55 --- count:     2\n",
      "value: 57 --- count:     1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Tally the total number of training captions with each length.\n",
    "counter = Counter(data_loader.dataset.caption_lengths)\n",
    "lengths = sorted(counter.items(), key=lambda pair: pair[1], reverse=True)\n",
    "for value, count in lengths:\n",
    "    print('value: %2d --- count: %5d' % (value, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled indices: [378419, 322658, 337636, 219149, 168679, 149092, 46511, 375540, 222745, 339642]\n",
      "images.shape: torch.Size([10, 3, 224, 224])\n",
      "captions.shape: torch.Size([10, 15])\n",
      "images: tensor([[[[ 1.4783,  1.4954,  1.4612,  ...,  1.5982,  1.5982,  1.6324],\n",
      "          [ 1.4954,  1.5125,  1.4783,  ...,  1.5982,  1.6153,  1.6495],\n",
      "          [ 1.4954,  1.5125,  1.4783,  ...,  1.6495,  1.6324,  1.6324],\n",
      "          ...,\n",
      "          [ 1.6153,  1.6838,  1.7352,  ...,  1.9578,  1.9064,  1.9064],\n",
      "          [ 1.6324,  1.6324,  1.6838,  ...,  1.9578,  1.9407,  1.9578],\n",
      "          [ 1.7009,  1.6495,  1.6838,  ...,  1.9578,  1.9578,  1.9749]],\n",
      "\n",
      "         [[ 1.6408,  1.6583,  1.6232,  ...,  1.7633,  1.7633,  1.7983],\n",
      "          [ 1.6583,  1.6758,  1.6408,  ...,  1.7633,  1.7808,  1.8158],\n",
      "          [ 1.6583,  1.6758,  1.6408,  ...,  1.8158,  1.7983,  1.7983],\n",
      "          ...,\n",
      "          [ 1.7808,  1.8508,  1.9034,  ...,  2.1310,  2.0784,  2.0784],\n",
      "          [ 1.7983,  1.7983,  1.8508,  ...,  2.1310,  2.1134,  2.1310],\n",
      "          [ 1.8683,  1.8158,  1.8508,  ...,  2.1310,  2.1310,  2.1485]],\n",
      "\n",
      "         [[ 1.8557,  1.8731,  1.8383,  ...,  1.9777,  1.9777,  2.0125],\n",
      "          [ 1.8731,  1.8905,  1.8557,  ...,  1.9777,  1.9951,  2.0300],\n",
      "          [ 1.8731,  1.8905,  1.8557,  ...,  2.0300,  2.0125,  2.0125],\n",
      "          ...,\n",
      "          [ 1.9951,  2.0648,  2.1171,  ...,  2.3437,  2.2914,  2.2914],\n",
      "          [ 2.0125,  2.0125,  2.0648,  ...,  2.3437,  2.3263,  2.3437],\n",
      "          [ 2.0823,  2.0300,  2.0648,  ...,  2.3437,  2.3437,  2.3611]]],\n",
      "\n",
      "\n",
      "        [[[-0.9363, -0.9363, -0.9363,  ...,  0.2453,  0.2624,  0.2967],\n",
      "          [-0.9534, -0.9363, -0.9534,  ...,  0.2453,  0.2111,  0.2796],\n",
      "          [-0.9020, -0.9020, -0.9020,  ...,  0.2282,  0.2111,  0.2282],\n",
      "          ...,\n",
      "          [-1.4843, -1.5014, -1.4672,  ..., -1.6042, -1.6042, -1.6042],\n",
      "          [-1.4329, -1.4500, -1.4843,  ..., -1.6042, -1.5870, -1.6042],\n",
      "          [-1.4329, -1.4500, -1.4672,  ..., -1.6042, -1.6042, -1.6042]],\n",
      "\n",
      "         [[-1.0203, -1.0028, -1.0378,  ...,  0.7479,  0.7479,  0.7829],\n",
      "          [-1.0553, -1.0203, -1.0553,  ...,  0.7129,  0.6954,  0.7654],\n",
      "          [-1.0028, -1.0378, -1.0553,  ...,  0.6954,  0.6604,  0.6954],\n",
      "          ...,\n",
      "          [-1.9132, -1.9482, -1.9482,  ..., -1.9657, -1.9657, -1.9657],\n",
      "          [-1.8957, -1.9307, -1.9482,  ..., -1.9657, -1.9482, -1.9657],\n",
      "          [-1.9307, -1.9307, -1.9132,  ..., -1.9657, -1.9657, -1.9657]],\n",
      "\n",
      "         [[-0.3753, -0.3578, -0.4101,  ...,  0.9668,  0.9842,  1.0191],\n",
      "          [-0.4101, -0.3753, -0.4101,  ...,  0.9494,  0.9319,  1.0017],\n",
      "          [-0.3578, -0.3753, -0.3927,  ...,  0.9319,  0.9145,  0.9319],\n",
      "          ...,\n",
      "          [-1.2293, -1.2641, -1.2641,  ..., -1.2641, -1.2641, -1.2641],\n",
      "          [-1.2293, -1.2293, -1.2816,  ..., -1.2641, -1.2467, -1.2641],\n",
      "          [-1.2467, -1.2293, -1.2467,  ..., -1.2641, -1.2641, -1.2641]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1290,  2.1290,  2.1290,  ...,  0.8104,  0.7419,  0.7419],\n",
      "          [ 2.1290,  2.1290,  2.1290,  ...,  0.8447,  0.7591,  0.7248],\n",
      "          [ 2.1290,  2.1290,  2.1290,  ...,  1.0673,  0.8961,  0.7248],\n",
      "          ...,\n",
      "          [ 0.8618,  0.8104,  0.9646,  ..., -2.1008, -2.1008, -2.1008],\n",
      "          [ 0.7762,  0.9474,  1.2385,  ..., -2.1008, -2.1008, -2.0837],\n",
      "          [ 0.9474,  1.1872,  1.4269,  ..., -2.1179, -2.1008, -2.1008]],\n",
      "\n",
      "         [[ 2.3060,  2.3060,  2.3060,  ...,  0.8179,  0.7654,  0.6254],\n",
      "          [ 2.3235,  2.3235,  2.3235,  ...,  0.9055,  0.8704,  0.7829],\n",
      "          [ 2.3235,  2.3235,  2.3235,  ...,  0.9230,  0.9055,  0.8354],\n",
      "          ...,\n",
      "          [ 0.5028,  0.4503,  0.6779,  ..., -1.8606, -1.8782, -1.8782],\n",
      "          [ 0.5378,  0.7304,  1.1506,  ..., -1.8957, -1.9132, -1.8957],\n",
      "          [ 0.9755,  1.1155,  1.3606,  ..., -1.8957, -1.8782, -1.9132]],\n",
      "\n",
      "         [[ 2.4483,  2.4483,  2.4483,  ...,  0.6182,  0.5485,  0.3742],\n",
      "          [ 2.4483,  2.4483,  2.4483,  ...,  0.5485,  0.5136,  0.4614],\n",
      "          [ 2.4483,  2.4483,  2.4483,  ...,  0.6356,  0.5136,  0.5834],\n",
      "          ...,\n",
      "          [ 0.4265,  0.3219,  0.6182,  ..., -1.7173, -1.7347, -1.7347],\n",
      "          [ 0.3568,  0.6531,  1.2282,  ..., -1.7347, -1.7522, -1.7347],\n",
      "          [ 0.8448,  1.2282,  1.6640,  ..., -1.7522, -1.7347, -1.7522]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.5022,  0.4851,  0.5022,  ...,  0.5536,  0.5193,  0.5193],\n",
      "          [ 0.5193,  0.5022,  0.5193,  ...,  0.5364,  0.5193,  0.5193],\n",
      "          [ 0.5022,  0.5193,  0.5193,  ...,  0.5364,  0.5364,  0.5364],\n",
      "          ...,\n",
      "          [ 0.4679,  0.4679,  0.4508,  ...,  0.4851,  0.4851,  0.5022],\n",
      "          [ 0.4679,  0.4679,  0.4508,  ...,  0.4851,  0.5022,  0.5536],\n",
      "          [ 0.4679,  0.4679,  0.4508,  ...,  0.5022,  0.3652,  0.1939]],\n",
      "\n",
      "         [[ 0.6429,  0.6254,  0.6429,  ...,  0.6779,  0.6429,  0.6429],\n",
      "          [ 0.6429,  0.6429,  0.6429,  ...,  0.6604,  0.6429,  0.6429],\n",
      "          [ 0.6254,  0.6429,  0.6429,  ...,  0.6604,  0.6604,  0.6604],\n",
      "          ...,\n",
      "          [ 0.6254,  0.6078,  0.5903,  ...,  0.6254,  0.6078,  0.6078],\n",
      "          [ 0.6078,  0.6078,  0.5903,  ...,  0.6429,  0.6604,  0.6604],\n",
      "          [ 0.6078,  0.6078,  0.5903,  ...,  0.6078,  0.4853,  0.3277]],\n",
      "\n",
      "         [[ 0.9668,  0.9494,  0.9668,  ...,  0.9842,  0.9668,  0.9668],\n",
      "          [ 0.9494,  0.9494,  0.9494,  ...,  0.9668,  0.9668,  0.9668],\n",
      "          [ 0.9494,  0.9494,  0.9668,  ...,  0.9842,  0.9842,  0.9842],\n",
      "          ...,\n",
      "          [ 0.8797,  0.8622,  0.8448,  ...,  0.8797,  0.8797,  0.8797],\n",
      "          [ 0.8622,  0.8622,  0.8448,  ...,  0.8971,  0.9145,  0.9145],\n",
      "          [ 0.8622,  0.8622,  0.8448,  ...,  0.8622,  0.7402,  0.5834]]],\n",
      "\n",
      "\n",
      "        [[[-0.4397, -0.4226, -0.3883,  ..., -0.0458, -0.0629, -0.1314],\n",
      "          [-0.3883, -0.3541, -0.3541,  ..., -0.0458, -0.0287, -0.0972],\n",
      "          [-0.4739, -0.4054, -0.3712,  ..., -0.0458, -0.0801, -0.0458],\n",
      "          ...,\n",
      "          [-0.0972, -0.0458,  0.0227,  ..., -0.0287, -0.0458, -0.0116],\n",
      "          [-0.1314, -0.0458, -0.0801,  ...,  0.0056,  0.0056,  0.0227],\n",
      "          [-0.0629, -0.0458, -0.0629,  ..., -0.0116,  0.0398,  0.0056]],\n",
      "\n",
      "         [[-0.3200, -0.3025, -0.2675,  ...,  0.0826,  0.0651, -0.0049],\n",
      "          [-0.2675, -0.2325, -0.2325,  ...,  0.0826,  0.1001,  0.0301],\n",
      "          [-0.3550, -0.2850, -0.2500,  ...,  0.0826,  0.0476,  0.0826],\n",
      "          ...,\n",
      "          [ 0.0301,  0.0826,  0.1527,  ...,  0.1001,  0.0826,  0.1176],\n",
      "          [-0.0049,  0.0826,  0.0476,  ...,  0.1352,  0.1352,  0.1527],\n",
      "          [ 0.0651,  0.0826,  0.0651,  ...,  0.1176,  0.1702,  0.1352]],\n",
      "\n",
      "         [[-0.0964, -0.0790, -0.0441,  ...,  0.3045,  0.2871,  0.2173],\n",
      "          [-0.0441, -0.0092, -0.0092,  ...,  0.3045,  0.3219,  0.2522],\n",
      "          [-0.1312, -0.0615, -0.0267,  ...,  0.3045,  0.2696,  0.3045],\n",
      "          ...,\n",
      "          [ 0.2522,  0.3045,  0.3742,  ...,  0.3219,  0.3045,  0.3393],\n",
      "          [ 0.2173,  0.3045,  0.2696,  ...,  0.3568,  0.3568,  0.3742],\n",
      "          [ 0.2871,  0.3045,  0.2871,  ...,  0.3393,  0.3916,  0.3568]]],\n",
      "\n",
      "\n",
      "        [[[-0.6965, -0.6109, -0.7822,  ..., -0.9877, -1.0219, -1.2103],\n",
      "          [-0.3883, -0.5082, -0.6452,  ..., -1.0562, -1.0390, -1.0048],\n",
      "          [-0.0801, -0.5938, -0.8164,  ..., -1.0733, -1.0048, -0.9705],\n",
      "          ...,\n",
      "          [-1.0048, -1.0219, -0.8678,  ..., -0.7308,  0.0398,  0.3309],\n",
      "          [-0.6281, -0.9363, -1.1760,  ..., -0.8678, -0.9534, -0.8164],\n",
      "          [-0.8507, -0.9192, -1.0904,  ..., -0.7137, -0.8507, -0.7479]],\n",
      "\n",
      "         [[-0.3725, -0.3375, -0.5126,  ..., -0.6352, -0.8803, -0.9678],\n",
      "          [-0.1275, -0.2325, -0.3375,  ..., -0.9328, -1.0028, -1.0028],\n",
      "          [ 0.0826, -0.1975, -0.2675,  ..., -0.8978, -0.8978, -0.9328],\n",
      "          ...,\n",
      "          [-1.1954, -1.0203, -0.9503,  ..., -0.8627, -0.1625, -0.0224],\n",
      "          [-0.7227, -1.0378, -1.1604,  ..., -1.0028, -0.9678, -0.9328],\n",
      "          [-0.9853, -1.0728, -1.2129,  ..., -0.8277, -0.9678, -0.9678]],\n",
      "\n",
      "         [[-0.6715, -0.5147, -0.6367,  ..., -0.6367, -0.7064, -0.8981],\n",
      "          [-0.3578, -0.3404, -0.4798,  ..., -0.8110, -0.7587, -0.7761],\n",
      "          [-0.2358, -0.3578, -0.4973,  ..., -0.7936, -0.7064, -0.8110],\n",
      "          ...,\n",
      "          [-0.8981, -0.8458, -0.7238,  ..., -0.7761, -0.1661, -0.0267],\n",
      "          [-0.4450, -0.8284, -1.0201,  ..., -0.9678, -0.9156, -0.8284],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [-0.7761, -1.0201, -1.0898,  ..., -0.8458, -0.8110, -0.8633]]]])\n",
      "captions: tensor([[    0,     3,  2757,    26,    13,     3,    98,    39,   319,\n",
      "           364,   161,     3,   371,    18,     1],\n",
      "        [    0,   454,   224,    77,   613,   192,     3,    59,   112,\n",
      "            86,    15,    21,  1716,    18,     1],\n",
      "        [    0,     3,   169,    77,    20,  2153,   224,    77,   121,\n",
      "            13,     3,  3558,   713,    18,     1],\n",
      "        [    0,   250,    52,   193,   454,     6,    91,   170,   364,\n",
      "           161,     3,  5292,  3400,   902,     1],\n",
      "        [    0,     3,    98,   286,    39,   257,    13,     3,   325,\n",
      "           364,   161,     3,   119,    18,     1],\n",
      "        [    0,     3,    91,   224,   111,     3,   535,   112,    21,\n",
      "             3,   818,    13,   109,    18,     1],\n",
      "        [    0,   322,   407,    39,     3,   713,    86,  2831,    21,\n",
      "            47,     9,  2527,   381,    18,     1],\n",
      "        [    0,     3,  1430,  1199,    77,    71,     3,  2357,    21,\n",
      "            16,  2357,  1463,  3223,    18,     1],\n",
      "        [    0,  2323,  2570,    52,  5928,    71,    32,   353,   207,\n",
      "            32,   519,  4761,   537,    18,     1],\n",
      "        [    0,     3,   407,    53,   417,    32,   498,    21,   160,\n",
      "          3670,   161,    32,   196,    18,     1]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Randomly sample a caption length, and sample indices with that length.\n",
    "# with 10 sampled indices is becasue batch_size = 10\n",
    "indices = data_loader.dataset.get_train_indices()\n",
    "print('sampled indices:', indices)\n",
    "\n",
    "# Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "data_loader.batch_sampler.sampler = new_sampler\n",
    "    \n",
    "# Obtain the batch.\n",
    "images, captions = next(iter(data_loader))\n",
    "    \n",
    "print('images.shape:', images.shape)\n",
    "print('captions.shape:', captions.shape)\n",
    "\n",
    "# (Optional) Uncomment the lines of code below to print the pre-processed images and captions.\n",
    "print('images:', images)\n",
    "print('captions:', captions)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
